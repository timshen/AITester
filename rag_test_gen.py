import os
import json
import pandas as pd
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import requests
from json_repair import repair_json
import PyPDF2
import uuid
import re
from datetime import datetime

def load_cases(csv_path="test_cases.csv"):
    try:
        if not os.path.exists(csv_path):
            os.makedirs(os.path.dirname(csv_path) if os.path.dirname(csv_path) else ".", exist_ok=True)
            with open(csv_path, 'w', encoding='utf-8') as f:
                f.write("éœ€æ±‚æè¿°,æµ‹è¯•ç”¨ä¾‹\n")
            return pd.DataFrame(columns=['éœ€æ±‚æè¿°', 'æµ‹è¯•ç”¨ä¾‹'])
            
        df = pd.read_csv(csv_path)
        
        if 'éœ€æ±‚æè¿°' not in df.columns or 'æµ‹è¯•ç”¨ä¾‹' not in df.columns:
            st.warning(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—ï¼ˆéœ€è¦'éœ€æ±‚æè¿°'å’Œ'æµ‹è¯•ç”¨ä¾‹'åˆ—ï¼‰ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
            return pd.DataFrame(columns=['éœ€æ±‚æè¿°', 'æµ‹è¯•ç”¨ä¾‹'])
        
        def safe_parse_json(json_str):
            if pd.isna(json_str):
                return []
            try:
                cleaned_str = str(json_str).replace("'", "\"").strip()
                return json.loads(repair_json(cleaned_str))
            except Exception as e:
                print(f"JSONè§£æé”™è¯¯: {e}, æ•°æ®: {json_str[:100]}...")
                return []
        
        df['æµ‹è¯•ç”¨ä¾‹'] = df['æµ‹è¯•ç”¨ä¾‹'].apply(safe_parse_json)
        return df
        
    except Exception as e:
        st.error(f"CSVæ–‡ä»¶åŠ è½½å¤±è´¥ï¼š{str(e)}ï¼ˆåˆ›å»ºäº†æ–°çš„test_cases.csvæ–‡ä»¶ç»“æ„ï¼‰")
        try:
            with open(csv_path, 'w', encoding='utf-8') as f:
                f.write("éœ€æ±‚æè¿°,æµ‹è¯•ç”¨ä¾‹\n")
            st.info("å·²åˆ›å»ºæ–°çš„test_cases.csvæ–‡ä»¶ï¼Œå¯ä»¥å¼€å§‹æ·»åŠ æµ‹è¯•ç”¨ä¾‹äº†ã€‚")
        except Exception:
            pass
        return pd.DataFrame(columns=['éœ€æ±‚æè¿°', 'æµ‹è¯•ç”¨ä¾‹'])

def load_knowledge_segments(csv_path="knowledge_segments.csv"):
    try:
        if os.path.exists(csv_path):
            return pd.read_csv(csv_path)
        else:
            return pd.DataFrame(columns=['segment_id', 'document_name', 'page_num', 'content'])
    except Exception as e:
        st.error(f"çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼š{str(e)}")
        return pd.DataFrame(columns=['segment_id', 'document_name', 'page_num', 'content'])

def process_pdf(uploaded_file):
    filename = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:8]}.pdf"
    filepath = os.path.join("temp", filename)
    
    os.makedirs("temp", exist_ok=True)
    
    with open(filepath, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    segments = []
    try:
        pdf_reader = PyPDF2.PdfReader(filepath)
        total_pages = len(pdf_reader.pages)
        
        for page_num in range(total_pages):
            page = pdf_reader.pages[page_num]
            text = page.extract_text()
            
            paragraphs = re.split(r'\n\s*\n', text)
            for i, paragraph in enumerate(paragraphs):
                paragraph = paragraph.strip()
                if len(paragraph) > 20:
                    segments.append({
                        'segment_id': f"{filename}_{page_num}_{i}",
                        'document_name': uploaded_file.name,
                        'page_num': page_num + 1,
                        'content': paragraph
                    })
        
        return segments, len(segments), total_pages
    except Exception as e:
        st.error(f"PDFå¤„ç†å¤±è´¥ï¼š{str(e)}")
        if os.path.exists(filepath):
            os.remove(filepath)
        return [], 0, 0

def save_knowledge_segments(segments, csv_path="knowledge_segments.csv"):
    df_new = pd.DataFrame(segments)
    
    if os.path.exists(csv_path):
        df_existing = pd.read_csv(csv_path)
        df_combined = pd.concat([df_existing, df_new], ignore_index=True)
    else:
        df_combined = df_new
    
    df_combined.to_csv(csv_path, index=False)
    return len(df_combined)

def find_similar_cases(new_req, df, top_k=3):
    if df.empty:
        return []
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(df['éœ€æ±‚æè¿°'].tolist() + [new_req])
    similarity = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])
    top_indices = similarity.argsort()[0][-top_k:][::-1]
    return [df.iloc[i]['æµ‹è¯•ç”¨ä¾‹'] for i in top_indices]

def find_relevant_knowledge(query, knowledge_df, top_k=3):
    if knowledge_df.empty:
        return []
    
    vectorizer = TfidfVectorizer()
    documents = knowledge_df['content'].tolist()
    try:
        tfidf_matrix = vectorizer.fit_transform(documents + [query])
        similarity = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])
        top_indices = similarity.argsort()[0][-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            segment = knowledge_df.iloc[idx]
            results.append({
                'document': segment['document_name'],
                'page': segment['page_num'],
                'content': segment['content']
            })
        return results
    except Exception as e:
        st.error(f"çŸ¥è¯†æœç´¢å¤±è´¥ï¼š{str(e)}")
        return []

def generate_test_cases(prompt, history_cases=None, knowledge_segments=None, max_cases=10, temp=0.7, use_enhancement=True):
    headers = {"Authorization": "Bearer sk-xxxxxx", 
               "Content-Type": "application/json"}
    
    system_prompt = ""
    
    if use_enhancement and (history_cases or knowledge_segments):
        context = "\n".join([f"å†å²ç”¨ä¾‹{idx+1}: {case}" for idx, case in enumerate(history_cases or [])]) if history_cases else ""
        
        knowledge_context = ""
        if knowledge_segments and len(knowledge_segments) > 0:
            knowledge_context = "å‚è€ƒçŸ¥è¯†ï¼š\n" + "\n\n".join([
                f"æ–‡æ¡£ã€Š{item['document']}ã€‹ç¬¬{item['page']}é¡µï¼š{item['content']}"
                for item in knowledge_segments
            ])
        
        system_prompt = f"""ä½ æ˜¯ä¸€åæµ‹è¯•è€å¸æœºï¼Œè¯·åŸºäºä»¥ä¸‹å†å²ç”¨ä¾‹å’ŒçŸ¥è¯†åº“ç”Ÿæˆ{max_cases}æ¡æ–°ç”¨ä¾‹ï¼š
{context}

{knowledge_context}

è¦æ±‚ï¼š
1. è¾“å‡ºæ ¼å¼ä¸ºJSONæ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«å­—æ®µï¼š
   - ç”¨ä¾‹ç¼–å·ï¼ˆæ ¼å¼TC-æ¨¡å—-åºå·ï¼Œå¦‚TC-LOGIN-01ï¼‰
   - æ­¥éª¤ï¼ˆç®€æ˜æ­¥éª¤æè¿°ï¼‰
   - é¢„æœŸï¼ˆé¢„æœŸç»“æœï¼‰
   - ä¼˜å…ˆçº§ï¼ˆ1-5ï¼Œ1ä¸ºæœ€é«˜ï¼‰
2. åŒ…å«æ­£å‘å’Œå¼‚å¸¸åœºæ™¯
3. æŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½æ’åº
4. ä»…è¿”å›åˆæ³•JSONï¼Œä¸è¦é¢å¤–è§£é‡Š"""
    else:
        system_prompt = f"""ä½ æ˜¯ä¸€åæµ‹è¯•è€å¸æœºï¼Œè¯·ä¸ºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆ{max_cases}æ¡æµ‹è¯•ç”¨ä¾‹ï¼š

è¦æ±‚ï¼š
1. è¾“å‡ºæ ¼å¼ä¸ºJSONæ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«å­—æ®µï¼š
   - ç”¨ä¾‹ç¼–å·ï¼ˆæ ¼å¼TC-æ¨¡å—-åºå·ï¼Œå¦‚TC-LOGIN-01ï¼‰
   - æ­¥éª¤ï¼ˆç®€æ˜æ­¥éª¤æè¿°ï¼‰
   - é¢„æœŸï¼ˆé¢„æœŸç»“æœï¼‰
   - ä¼˜å…ˆçº§ï¼ˆ1-5ï¼Œ1ä¸ºæœ€é«˜ï¼‰
2. åŒ…å«æ­£å‘å’Œå¼‚å¸¸åœºæ™¯
3. æŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½æ’åº
4. ä»…è¿”å›åˆæ³•JSONï¼Œä¸è¦é¢å¤–è§£é‡Š"""
    
    try:
        response = requests.post(
            "https://api.lkeap.cloud.tencent.com/v1",
            headers=headers,
            json={
                "model": "deepseek-r1",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": temp
            },
            verify=False
        )
        content = response.json()["choices"][0]["message"]["content"]
        print(content)
        return json.loads(repair_json(content))
    except Exception as e:
        st.error(f"AIç½¢å·¥äº†ï¼š{str(e)}ï¼ˆæ£€æŸ¥API_KEYæ˜¯ä¸æ˜¯å……è¯è´¹é€çš„ï¼Ÿï¼‰")
        return []

def apply_custom_styles():
    st.markdown("""
    <style>
        .main .block-container {
            padding-top: 2rem;
            position: relative;
        }
        
        h1, h2, h3 {
            color: #1E3A8A;
        }
        
        .css-card {
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 15px;
            background-color: white;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        
        .upload-section {
            border: 2px dashed #3B82F6;
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            margin-bottom: 20px;
            background-color: #F3F4F6;
        }
        
        .info-box {
            background-color: #E0F2FE;
            padding: 10px 15px;
            border-radius: 6px;
            margin-bottom: 15px;
        }
        
        .success-box {
            background-color: #D1FAE5;
            padding: 10px 15px;
            border-radius: 6px;
            margin-bottom: 15px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("""

    
    <div style="
        position: fixed;
        top: 0;
        left: 0;
        width: 100vw;
        height: 100vh;
        z-index: -2;
        pointer-events: none;
        background-image: repeating-linear-gradient(
            45deg,
            rgba(180, 180, 180, 0.05),
            rgba(180, 180, 180, 0.05) 150px,
            rgba(180, 180, 180, 0.1) 150px,
            rgba(180, 180, 180, 0.1) 300px
        );
    "></div>
    """, unsafe_allow_html=True)

def main():
    st.set_page_config(page_title="ğŸ¤– AIæµ‹è¯•å°ç§˜ä¹¦", layout="wide")
    apply_custom_styles()
    
    st.title("ğŸ’¡ AIæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼ˆå†…ç½®çŸ¥è¯†åº“å¢å¼ºç‰ˆï¼‰")
    st.markdown("<p style='color:#4B5563;'>ä¸Šä¼ ä¸“ä¸šæ–‡æ¡£ï¼Œè®¾è®¡å‡ºæ›´ä¸“ä¸šçš„æµ‹è¯•ç”¨ä¾‹</p>", unsafe_allow_html=True)
    
    if 'knowledge_segments_count' not in st.session_state:
        st.session_state.knowledge_segments_count = 0
        
    knowledge_df = load_knowledge_segments()
    if not knowledge_df.empty:
        st.session_state.knowledge_segments_count = len(knowledge_df)
    
    test_cases_df = load_cases()
    
    tab1, tab2 = st.tabs(["ğŸ“ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹", "ğŸ“š çŸ¥è¯†åº“ç®¡ç†"])
    
    with tab1:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("<h3>è¾“å…¥éœ€æ±‚æè¿°</h3>", unsafe_allow_html=True)
            
            with st.form("magic_form"):
                user_input = st.text_area("æè¿°ä½ çš„æµ‹è¯•éœ€æ±‚", height=150,
                                        placeholder="ç¤ºä¾‹ï¼šè´­ç‰©è½¦éœ€æ”¯æŒæ·»åŠ å•†å“ã€åº“å­˜ä¸è¶³æç¤ºã€æ‰¹é‡åˆ é™¤")
                
                col_button1, col_button2 = st.columns([1, 3])
                with col_button1:
                    submitted = st.form_submit_button("âœ¨ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹", use_container_width=True)
                with col_button2:
                    use_knowledge = st.checkbox("ä½¿ç”¨çŸ¥è¯†åº“å¢å¼º", value=True, help="å‹¾é€‰åå°†ä½¿ç”¨çŸ¥è¯†åº“å’Œå†å²ç”¨ä¾‹å¢å¼ºæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ")
        
        with col2:
            st.markdown("<h3>çŸ¥è¯†åº“çŠ¶æ€</h3>", unsafe_allow_html=True)
            
            st.markdown(f"""
            <div class="info-box">
                <p><b>ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡</b></p>
                <p>â€¢ æ–‡æ¡£æ®µè½ï¼š{st.session_state.knowledge_segments_count} æ¡</p>
                <p>â€¢ å†å²ç”¨ä¾‹ï¼š{len(test_cases_df)} æ¡</p>
            </div>
            """, unsafe_allow_html=True)
            
            with st.expander("å¦‚ä½•è·å¾—æ›´å¥½çš„ç»“æœï¼Ÿ"):
                st.markdown("""
                1. **ä¸Šä¼ é¢†åŸŸæ–‡æ¡£**ï¼šåœ¨"çŸ¥è¯†åº“ç®¡ç†"é€‰é¡¹å¡ä¸Šä¼ ç›¸å…³PDF
                2. **æè¿°éœ€æ±‚ç»†èŠ‚**ï¼šè¶Šè¯¦ç»†çš„éœ€æ±‚æè¿°è¶Šèƒ½è·å¾—ç²¾å‡†çš„æµ‹è¯•ç”¨ä¾‹
                3. **è¿­ä»£ä¼˜åŒ–**ï¼šåŸºäºç”Ÿæˆç»“æœï¼Œè°ƒæ•´éœ€æ±‚æè¿°å†æ¬¡ç”Ÿæˆ
                """)
    
        if submitted and user_input:
            if use_knowledge:
                with st.spinner("ğŸ” æ­£åœ¨æœç´¢ç›¸å…³çŸ¥è¯†..."):
                    similar_cases = find_similar_cases(user_input, test_cases_df)
                    relevant_knowledge = find_relevant_knowledge(user_input, knowledge_df)
                
                with st.spinner("ğŸ¤– AIæ­£åœ¨ç”Ÿæˆå¢å¼ºæµ‹è¯•ç”¨ä¾‹..."):
                    new_cases = generate_test_cases(user_input, similar_cases, relevant_knowledge, use_enhancement=True)
                
                st.success("âœ… æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼(ä½¿ç”¨çŸ¥è¯†åº“å¢å¼º)")
                
                if relevant_knowledge:
                    with st.expander("ğŸ“‘ å‚è€ƒçš„é¢†åŸŸçŸ¥è¯†", expanded=True):
                        for i, segment in enumerate(relevant_knowledge):
                            st.markdown(f"""
                            <div style="margin-bottom: 10px; padding: 10px; border-left: 3px solid #3B82F6; background-color: #F3F4F6;">
                                <p><b>æ–‡æ¡£ï¼š</b>{segment['document']} (ç¬¬{segment['page']}é¡µ)</p>
                                <p>{segment['content']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                
                if similar_cases:
                    with st.expander("ğŸ‘‰ å‚è€ƒçš„å†å²ç”¨ä¾‹", expanded=True):
                        st.json(similar_cases)
            else:
                with st.spinner("ğŸ¤– AIæ­£åœ¨ç”ŸæˆåŸºç¡€æµ‹è¯•ç”¨ä¾‹..."):
                    new_cases = generate_test_cases(user_input, use_enhancement=False)
                
                st.success("âœ… æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼(ä»…ä½¿ç”¨åŸå§‹éœ€æ±‚)")
            
            st.subheader("ğŸ¯ ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹")
            st.dataframe(pd.DataFrame(new_cases), use_container_width=True)
    
    with tab2:
        st.markdown("<h3>ğŸ“¤ ä¸Šä¼ çŸ¥è¯†æ–‡æ¡£</h3>", unsafe_allow_html=True)
        
        upload_col1, upload_col2 = st.columns([3, 1])
        
        with upload_col1:
            uploaded_file = st.file_uploader("ä¸Šä¼ PDFæ–‡æ¡£ï¼ˆå°†è¢«åˆ†å‰²å¹¶å­˜å…¥çŸ¥è¯†åº“ï¼‰", type="pdf")
            
        with upload_col2:
            if uploaded_file is not None:
                if st.button("å¤„ç†æ–‡æ¡£", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨å¤„ç†PDFæ–‡æ¡£..."):
                        segments, segment_count, page_count = process_pdf(uploaded_file)
                        if segments:
                            total_count = save_knowledge_segments(segments)
                            st.session_state.knowledge_segments_count = total_count
                            st.success(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼ä» {page_count} é¡µä¸­æå–äº† {segment_count} ä¸ªçŸ¥è¯†æ®µè½ã€‚")
                            knowledge_df = load_knowledge_segments()
        
        if not knowledge_df.empty:
            st.markdown("<h3>ğŸ“š çŸ¥è¯†åº“å†…å®¹</h3>", unsafe_allow_html=True)
            
            docs = knowledge_df['document_name'].unique()
            st.markdown(f"å½“å‰çŸ¥è¯†åº“åŒ…å« **{len(docs)}** ä¸ªæ–‡æ¡£ï¼Œå…± **{len(knowledge_df)}** ä¸ªçŸ¥è¯†æ®µè½ã€‚")
            
            selected_doc = st.selectbox("é€‰æ‹©è¦æŸ¥çœ‹çš„æ–‡æ¡£", ["æ‰€æœ‰æ–‡æ¡£"] + list(docs))
            
            if selected_doc == "æ‰€æœ‰æ–‡æ¡£":
                display_df = knowledge_df
            else:
                display_df = knowledge_df[knowledge_df['document_name'] == selected_doc]
            
            for _, row in display_df.head(20).iterrows():
                st.markdown(f"""
                <div style="margin-bottom: 10px; padding: 15px; border-radius: 8px; background-color: #F8FAFC; border: 1px solid #E2E8F0;">
                    <p style="margin:0; color: #6B7280; font-size: 0.8rem;">æ–‡æ¡£ï¼š{row['document_name']} | ç¬¬{row['page_num']}é¡µ</p>
                    <p style="margin-top: 8px;">{row['content']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            if len(display_df) > 20:
                st.info(f"ä»…æ˜¾ç¤ºå‰20æ¡è®°å½•ï¼Œå…± {len(display_df)} æ¡")

if __name__ == "__main__":
    main()
